{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_ExternalLab_AIML.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YYk8NG3yOIT9"},"source":["### A MNIST-like fashion product database\n","\n","In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tFO6PuxzOIT_"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"efNjNImfOIUC","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6c3f2f55-777e-4419-c67d-bcc6d3da366d","executionInfo":{"status":"ok","timestamp":1576394376409,"user_tz":-330,"elapsed":1110,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["%tensorflow_version 2.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6GjXWYzpKvWG","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l9C4aAIGOIUH","outputId":"1aecbf15-3109-490e-9266-bc9ef5059876","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1576394377731,"user_tz":-330,"elapsed":2370,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["tf.__version__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.15.0'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HcoZBStrOIUQ"},"source":["### Collect Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XA1WsFSeOIUS","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b98b30bb-cc56-4f32-cb35-7b02c9084f45","executionInfo":{"status":"ok","timestamp":1576394377733,"user_tz":-330,"elapsed":2346,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["import keras"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qnbx7TyQOIUY","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"f817cbe5-ca84-4db8-9e54-0ed8b78d011d","executionInfo":{"status":"ok","timestamp":1576394379976,"user_tz":-330,"elapsed":4448,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UbiHj5YPOIUc","outputId":"2df542f9-203b-494a-ca4e-149825c4398b","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1576394379978,"user_tz":-330,"elapsed":4405,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(testY[0:5])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[9 2 1 1 6]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lDAYzkwyOIUj"},"source":["### Convert both training and testing labels into one-hot vectors.\n","\n","**Hint:** check **tf.keras.utils.to_categorical()**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vBlfYlANOIUk","colab":{}},"source":["trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n","testY = tf.keras.utils.to_categorical(testY, num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RHV3b9mzOIUq","outputId":"6e5f31d2-3a60-45e6-9d06-e4f921d60722","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1576394379980,"user_tz":-330,"elapsed":4375,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(trainY.shape)\n","print('First 5 examples now are: ', trainY[0:5])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FwhQ8e7VOIUw"},"source":["### Visualize the data\n","\n","Plot first 10 images in the triaining set and their labels."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AvDML2OoOIUx","outputId":"b57a5596-0ae6-405c-bbf7-7ad3eca6b678","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"ok","timestamp":1576395436421,"user_tz":-330,"elapsed":1281,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["import numpy as np\n","\n","# visualizing the first 10 images in the dataset and their labels\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 1))\n","for i in range(10):\n","    plt.subplot(1, 10, i+1)\n","    plt.imshow(trainX[i].reshape(28, 28), cmap=\"gray\")\n","    plt.axis('off')\n","    print('label for each of the below image: %s' % (np.argmax(trainY[0:10][i])))\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["label for each of the below image: 9\n","label for each of the below image: 0\n","label for each of the below image: 0\n","label for each of the below image: 3\n","label for each of the below image: 0\n","label for each of the below image: 2\n","label for each of the below image: 7\n","label for each of the below image: 2\n","label for each of the below image: 5\n","label for each of the below image: 5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO1daXhU1Rl+Z80kM2xB9ihBBMUFEdTi\ngiCI2lZUUAvWtT76VGxL61at+lhta6nS1q3WurRVpOpTC9aqqFULLVUrWmuRIopLKgRRspGQzJLJ\nTH9M3++eOffOZDKZJcbz/plk5s6de+5Z7ve93/t9x5VMJmFgYGBgYGBg0J/hLvcFGBgYGBgYGBgU\nG8bgMTAwMDAwMOj3MAaPgYGBgYGBQb+HMXgMDAwMDAwM+j2MwWNgYGBgYGDQ72EMHgMDAwMDA4N+\nD2+2D10u12c6Zz2ZTLq6OyaXNrpcLmRL399vv/0AAL/4xS8AAI899hj+9a9/AQBisRgAoLOzEwce\neCAAYP78+QCA999/HwCwbNkytLS0dHcZjihUGzNh+PDhAIDzzz8fALB8+XIAwI4dO7J+b8qUKQCs\ne7Ny5Up0dnbmdQ3dtTHf9tXW1mLWrFkAgFNOOQUA0NjYCABYsWIF3njjDQBWG0477TTMmTMHANDR\n0SHHAcC9996bzyUAKH4f5ovRo0cDALZv397rc/W2jS6Xi+dx/JzjdPbs2QCACy+8EADQ0tKCt99+\nG4A1FwcPHowjjzwSAPCPf/wDAHDNNdcAAMLhsONv51K+o6/2YyFRiLnIvvz/+TIeN3PmTACpdXLb\ntm22z2trawEAhx12GIDUuttbmD5Mob+20ZVtwPXXRqtwamO2xZUP8kWLFuG0004DAHR1dQEAgsEg\nAKCyshJDhw7N+JvvvvsuACCRSAAA9t13X3zyyScAgOeeew4A8NOf/hQbN27s7vKLOnhDoRAWLVoE\nAPj2t78NwHpoNDQ0yN98HTBgACoqKgAANTU1AIAnnngCAPDKK6/kvSAVyuD54he/CAC49NJLAaQe\nbn6/HwAQiUQApNoAAAceeCBGjBgBAKirqwMAxONxfPzxxwCAXbt2AYC0d8yYMXjxxRcBAEuWLMnl\ncgTF7MMXX3wRQ4YMAWAZcxdddBEAq10qRo8ejTVr1gBIjWMA+O9//wsAOPHEE9He3p7PZRR0Lu6x\nxx4ArDF53HHHST/w+vj/fvvtJ31KdHZ2ygOU/cm2NjU14W9/+xsA4M477wQANDc359DCz/eDhMil\nfW63W9Y+oqamBhdccAEA4PLLLwcADBw4MKdr4vobj8cBAFdddRVuv/12x98FYPttFaYPU+ivbTQG\nTw5tHDhwoDAbkydPBpCaPG1tbQCshyUZjK6uLvh8PgDAoEGDAKQWYk40p3seCAQAWAuv3+/HunXr\nAADnnHNOxmsr9uA944wzAFie77XXXgsg9WCkQcCHS3NzM3bv3g0AeP755wEAjzzyCICU8fTHP/4x\nr2soxCI7fvx43HDDDQAgxmVVVZVtEeSiueeee8p3+VkikRBDh8exz5uamjBmzBgAELbuiiuu6LZt\nQHH7cO3atRg/fjwAq584xtra2rBy5UoAwNlnnw0A8Hg8Mp7ZDvb9wQcfnM8lACicwTN+/Hg8+eST\nAKx+jEQiaXMPAKLRKIBUv4RCIdtnNHSHDRsGAPB6U2S33++Xz8ji/epXv8Ljjz9etDZ+ltCbuehk\ncJBFnTBhgqyBvO80XgOBgBidHJOjRo1CVVVV2vEc16FQCE1NTQCAF154AQBw1llnZb2OXNvXXRvz\nhcvlsl2X+pxQWTH9MxVkLl9++WUAKWcaSDnZ/E45x2mu7ciEhx56CLfeeisAa+xwXeOc//95Hdto\nNDwGBgYGBgYG/R4lZ3ic4uEDBgzA0UcfDQB45plnbMd7PB4Alled6bxEoS3ZF154AWPHjgVghQUS\niYR4hbwu9RporTPcwzaon2VrRzKZxKhRowAAJ5xwAgBg8+bNtuOLba3TM/r0008BWFqJJUuWSKiE\nFnZLSwv++c9/AgB+85vfAADGjRsHANi5cyeeffbZvK6hEAzPL3/5S2Eu6EGFQiHxKtmH9Bbj8biw\nOTwmkUhIWwmVTuf5qdVavnw5nn766V63D8i/D1euXIlDDz0UgNW26upqACl2g2ORYZzJkycLc8Lx\nzZAW9TH5oFBt/P3vfy8hLXrxPp9P5jyZHvZxNBoVz4/9U1FRIcwrmVinuUumx+fz4dRTTwUAYTCL\n2ca+jHzmolNY8pVXXgEAGZs7duyQucXjuGYmk0lhc9g3HR0dMvfYh6r+iu9xrDzxxBPSh9muqy8w\nPGxXrqAO8aCDDsKECRMAWJEItvH444+XeVDMNjo9353uczYdF/tO1b2SiZ44caLIJNifnKd81v7/\nnIbhMTAwMDAwMPh8ImuWVjHgdrvFgt1nn30ApDIqaJ0zbktvbP369TZmR7WGaSmqx6hsSm8wbdo0\nAMDYsWPR0NAAwPJ6PR6PeP7UbqheCD1NHt/V1SXXSguW19zW1iYiSrUdvE/MOMlVE1JI0KOlp0Rv\n/7LLLhNhMnUQH374oTBgPJ7t12O3pcYDDzwgYuWdO3cCSGlAKGjVM8hisZi0gWhtbXXM4uHxZA22\nbt0KADmxO8XGBx98gOnTpwOwxhY9PbVPKGCeMWMG6uvrAViaCI7rcoJs58iRI4V5o2cXj8flGpk4\noOohOI/4GggE5Dhd8NrV1SVjnmtQMBjEvHnzAFiaNIPcoXvw8+fPxxe+8AUAkHXP5XLJuqhrWJLJ\npOglOWbdbrf8zT7keE0kEtKfH330EYAUw8GkBUYRyrFxdqaEmGQy6cjsnHvuuQCsbMIZM2YASDHs\nzJ4km7NlyxbRtXznO98BALz55puFbkJWJJPJjDodpyiH1+uVNZXvcS0+5phjsGrVqrT3Nm/ejG98\n4xtp5+9J9q9heAwMDAwMDAz6PUrO8Hg8HrFkqQk47rjjxNJnHJce29y5c3H//fcDsLIynKxhZmIk\nEgnRKvQWxx57rFwTr4veh8fjEU/5qquuAmDVK9m2bZvUMGHaq9vtlhgjz8Vrnjp1Kr71rW8BQBqT\nxN86/fTTAZSH4dHZNZX14LWyJk9VVZWwXewf1UsrJ9avXy+6gZNPPhkA8OqrrwoDxfFGhioWi0n7\n6OlXVVXJ8a2trQAsdks9x9VXX13UtvQEmzZtsjGeZFFjsZh4h0Q4HBYPTW9rOUG92MiRI2VskeEJ\nBoMyTvV56nK5bB6nx+OR99TjgNS4ZZ+y//1+P+bOnQvAMDw9AcedvlavWrVK7i0Z1paWFhsrrjID\n9P6d1hG+p645Opu+a9curF69GoDFFnLd8nq9WfWhpQbrfnm9XtHnUOvEefDAAw+I7o6szrRp06Qm\nEZ81jKK89957pbl4ZF7r1XHAv1V2hnORGbJPP/20sK0cS5dddpkw0N3V5nJCyQ0eVVjEzqmtrZUG\ncWCzHs0hhxyCW265BQDw+uuvAwDeeustKSZ2+OGHp53r5Zdflgdbb0FDIx6P2yZvIBAQav2+++4D\nkKJNgZQB89vf/hYA8PWvfx0AsHHjRhGL8lw04G699VZccsklAKzJHggExHDjBJg4cSIAq45PKaAv\nNGy/x+PB4MGDM35PH4xsVzlxxx13ALDqt3z00UcS3qIRwHtOCh2w+qu9vV3awYWUxw0aNEio8r5g\nIBD19fWyqLAvee0ff/yxLJZsR319vbSXfchxXk7QMPN4PBg5ciQAqz1ut1uMUjodLOpZV1dnC5O3\nt7fLPaHRxPOfdNJJchzHdygUkhCYQe7QDR2KTVtaWuRBxmSQlpYWW2kIIluShwrVuVLXKSDV5wyd\n0Ih49NFHHa+zmMj0cK6qqpKUchpira2t+PWvfw3Aqh3G8X3rrbdKAgnP+c4774gMgwY6x3IpDZ5s\naf8sZULDbejQoWLM8TOusc3NzXIvKBdgUkze19arbxsYGBgYGBgYfAZQMrdb9fhpfdKya2trEw+K\nLAZfX3vtNbFOGQI64ogjsGDBAgAWJfbaa68BSAl81QJEvQELrW3dulWsVjUtWa8EyrTr9vZ27L//\n/gCsMNTjjz8uwkdasCoVSa9GFVPSQqbw7ogjjgBQWoaH95ztpsfg8XjSwnuAc2ovXynwLhdU2pol\nEG666Sb5XE1HB1ICSHqE7C+v1ytjS/c63W63FMTrS9i+fbvMET2ME4lEsGnTJgAW6+N2u21VpMst\nOAcsb3zdunVSKoEpqz/+8Y8dSzYAKc+ZYla+BoNBGY9kfxiq+t73vidrCT3Ojo4O7L333gVv0+cN\nXL8Ai1nThceAcxg8lzGofk8/r8/nkz7nc4djqpThdq6VujA7FArZylrMmjVLIgQnnngiACvyAVil\nQojhw4dLqQZKC1i9+qWXXsqpcn8hoLeRhU9vu+02YU3JKB9wwAESojrggAMApIqlAim2meOE6253\nkYLuEpYMw2NgYGBgYGDQ71E0hiebRf7DH/4QgCUeAyzBJz1san2OPvposchpMb7xxhvC+vB4pqrt\nvffeor3JF7Swqe9QNTxsV2VlpQhc9e9Fo1FpG1kEl8tl87RVj4exWVX0y/aSaWBK4oMPPtir9vUE\nelq5U1qo03vsFzIhhSoVkC9UXQCF5O+//74URqR3Rc8jkUjIe2zD7t27RdCqt4/p+n0NDQ0Nsski\nWRC2y+Vy2TymWCxm847z3fS1kKCOL5FIyF5f3KB34MCB0jZeO3VUjY2Nsh0B26EyANQG0Lt8//33\nhUGizqSxsbFgrHFvkC3dV2cMsglxnfayUqGXzSgUA8J1zO/323Qz6vqoFp4DUm3RNYRutzujvlA9\nB/vN7/cLm8f+LUcSSKbthcLhsLSHyTwrVqzAxRdfnPO5hw4dKlEH6l3Z/oqKiqz7OxYS+npBPd35\n559ve2Y6gc/dQCCAt956C0Cq4CiQek7qDJL6bO5OfF40gyfbJOG+KDQKwuGw0OdcgBlKiUQiafUV\ngNSDnwIvDhIKuPKt5quCWVf83d27d9tqPUQiEbm5NMg4oKqrq2XCkRbv7OyUBw1pOtJ7CxcuFBEX\nF4VBgwalLRDq75QSamVTAGni8mx0NNEXHhSZ4Ha7JUuEY4vjsLW11baxqCq41yeWTi/3Fai72uui\nZTUsx37z+Xy2bJlcN88sJkjlz5kzRzbtZZLAgw8+iMWLFwOw5hSzU0KhkK0OiN/vl75kv3PX+7a2\nNpn/PKa5uVlC6Fx3GDooJTKtqU7VbZ0Wft6j6667ThwrJxTawKU0gBmera2tEl7iPQ4EAjYHQ93D\nTjcU1Pd0qHXQuEYNGTJEfqucGVmZ+rCtrU2yrvgKpD9v9O/riSGjRo2ScUnHjYkUo0ePFoF4udDY\n2GhzgJ3GGh2aBQsWyNozc+ZMAMDNN99sM5bV/7sz6kxIy8DAwMDAwKDfoyy5wvq+KG63WxgECiZJ\nfdXW1ooFq4ZOeA5ad3oOf2/AnWaZ/rrPPvsIVUhR8ZYtW+S3WQVT9Uj0tEiv12tjRNj+trY2ESKz\nXWrtCYa78t1tvDfQxbkqnaiXElBBdoAMDxm4ckL3HLdt2ybpyPxM2W9GmBC1FAFZN3pc9FopvANg\n22Ot3NBZNm3vIADWPenq6pL26uGhcuInP/kJgJRHyPnA0hTz5s3D9ddfn3Y8PcdoNGqrCaWGqNnH\nZJSbm5uxfv16ABY7tmbNGmzZsgVAeZgdHbpn7zTOzjzzTBxyyCEAgDPOOAOAxR43NDSISPvMM8+0\nfZfM5ne/+10AwI9+9KNeXa9anZ7XrVe6Vistq+s8/9fnbiaGmZ/xnqj7MPI4Vojva9BDNeq6mss+\nW8OGDZMwLO8NzxkKhcq+HqlMpMrs6Ovl8uXLAaTGLdtNxlZNJiGYIHTXXXdJPb9MMAyPgYGBgYGB\nQb9H0UXLumUaCoWkCjE9z2g0KtoJxlnJ+AwePFjYHrIffr8/reAbAGzYsEHO31uty9133532OmTI\nENmFlnHwmTNnirfHdD+KI30+X1aRrn5vIpGIrR0U1pUTQ4YMsYm1aaFnKgZG74RWu7ofEeP2fK/c\nqKurs+2MTS1VXV2deByMCzc3N9v2o+L3y+09ZUMmrYMq3lUFsXpfU+xZTnBPnTlz5sj8pj7hT3/6\nkzCILOGgMjgcd6pAm/3FdYbrzsCBA0XrwP2Ixo4dK8XqKJQu9R5Fqnes60D22WcfYXGoMTr++ONF\nLEqvl0xdbW0tvvSlL2X8rUWLFgGA7HfVW0ydOhWAxaYlk0mZN7zv4XBYWDZVK8fj9TGsMswE/3fa\ns6myslKeGWRB2L5XX321N80rGJy0KWQz9LY66baCwSDOO+88AMBTTz0FAHj44YcBpNpcqB0I8kUm\n/ZLet7z2pqYmeS4y8jN79mwZz1wTiCFDhuCrX/0qAODss892/C3D8BgYGBgYGBj0exQ9S0vfkmHh\nwoWijWH6WWVlpVh5jO1SixOLxYT9UbNHqF6n933XXXcBAKZMmVLwbQzUuD49+9mzZ0sb1T192Gbd\nalX39NEzgmKxmHih1A/1BUSj0TRNiw79PTXWTrD/d+3a1WeYHSIcDjt6jkDqutknfK+5uVk0O8zu\nIui99kVkYuNcLpfNc3S73bY0376gv2KcPhwOi7aG2rmjjjpKSkI47cysZ/ioc1HXTezYsUO8YrI4\nH3zwAbZu3QqgOEU/dX2KmkVGqHONmWgsebFw4ULx3llyYf369TImuVYydb+mpkZKgxDDhw/HwoUL\nAQA///nPAVhb2kybNq1XJf11RjuRSDhm5+glLbg+dnV1yZrupG8heI8qKiqEEVDXZP28ZPCcdEyF\nRD57PunQNaHqe0RDQ4MwkGRB77nnHgCp4n/lerY4tV9lljPdl23btsk6y22ZnnrqKTmembEcS2vX\nrpXxnwlFM3g4QPWJu3HjRnmIckKqG4pyceXDsbGxUY7jAygYDEq6GuktUlnLli2ThbC3UDegYzt4\ns1tbW23GXLaUwWxQBzHDYur7mWo3FBvJZDLv+jnq4tNXoBs38XhcjG41BZng3/yssrJSJhnr8ZAe\n78vQ67eoi40eklNr8/A91vEpJ1jp2Ov1iuiUhk9HR4dcK8MWarsybWIJWA9ELprDhg0T44GLbU1N\njRgZdNY++OCDXrfJKZwI2NdMID0dn2sdQ/2bNm2S9jO5YujQoRIOYXv4ENyxY4ec48orrwSQMiRZ\n84Rzluutuq9cPtC/r26krKaP60aMbih1B6e6PWzLrl27bIkJpar+Xsh122kMT5kyBQDw73//W6pH\nn3TSSQCAE044AUDKiKbRXmpka3+2elAHH3ywSDwog1m0aJGM8RtvvBGANYeff/75bq/FhLQMDAwM\nDAwM+j1yZnh0ClhNGaRlrVprmUScq1evFhGkWliPViA9bv5OIBCw0Z+dnZ22KotMLy7kzs5OKXQU\nAra2tmZksVQxaLb9YPg9NRyipgDnkopYTDiFBZy8rWyfqW3ItotuKaD//oABA0SkTC+Y1CmQoogB\nSyw/aNAgW1+zT9WiXn1NwKyPO3XuOh2jMyJ9geFRBf68LjIHVVVVtvVAFdvr+7q5XC7bmGVY2uPx\nSL8T1dXVMtfpaRaC4XGqEEwsWbIEAKTS7ogRI4TNJhPD77G4KZDOBuvjnWurugcgwxzz58+X9667\n7joAwCWXXAIgJQTPJALNBddccw0Aax2Nx+PCvHC+NTQ05L1nG/taLSbJ83NtbWtrk9Aenzunnnoq\ngOxhlb4CJ5aSBTJ5D++++26cc845ACz2b/Xq1QBS65MTc1hq6M9Fr9dri5DwmGg0Ks9Dp7Fx7bXX\nArDuzWOPPdbt7xuGx8DAwMDAwKDfIyeGR9XY5Oq9HnPMMQAgceejjjoKQMqTpvVJr0q18vQtDCoq\nKiTWSgtQTa/jOailWLBgQcF3rXa73XJ99A5UMTXvibrvlG6tqp4mP2MsuaqqyibY6wsIBAK2VFi1\n2Fe2fbJ0Sz6ZTNq2aig1dGZp586dUlKA8W2yOZFIRDxnekZ1dXVy7UyXpEiOnn9fw8SJE+W+6yUD\nADvbowp6ORYp1C4nnNgZloVQkx70Oab+rY5hsg36ljZut1u0Qezrrq4uGeO6WD1fTJ06FXPnzgUA\n7LvvvgAsTcno0aMlRZuavvr6ehlzPE5dF7kmqsX7uGbpgt9wOCxtO/zwwwGkipvyN8kksdhiVVUV\nLrroorzbSv2Vuq8T7zv3oKusrOy1uJffj8Vi0ha2XdUj8r26urpe/V4pobOtN9xwg7SHzN3pp58u\nfaYzksXYD099pqkMjFqAtzskEgnb/X/ttdcApAp+UoOkQmVjAWsM6cysE3IyeJwoV9Joo0ePlho1\nvLkLFizAxIkTAdjrlXR0dEhmFSumRiIRaQRFy3zIVFVVCe3KQXzMMcfIzWQIix06ffr0XJrUI6gd\nolak1RdSNaSjU+yAXYSnVrnNtlCXC+rDL5cQXaZzELmKD0uFGTNmSGiCk4YPgtbWVqH++aAJh8My\nLtWNb4GUmJVjl8Lm7jZpLAUmTZokDzB9c0YgPfRD6OJOGn5HHnlk2bMI1QzITz75BICVhaRCzYhU\njRm+6lV61XmqU/+qw9PbTXC/+c1vAkitkbxu9UENpPqHBgw/C4VC0m5KAmgMeb1e+YxGkMvlEqOC\n18zfCwQCMgYYMojH4yLSp6HL4/M18rhfF50INUSs72Wm9qvTXlp6HwJW3+mV66PRqMxZjvlIJCLz\nme0rRFV+HdkE8rl+l33u9/tlHDBjbtmyZQBSxiiv//LLLweQvjZTyExj85VXXunx9fBadGdXfe71\nVm6hro8rV64EYIVsv/a1r8ln6pjgWOC4YmZaLuhbTyADAwMDAwMDgyIgJ4Zn+vTpUreB6bhM01Tp\nXnoc8XhcBIW05GkdhsNh8RK/8pWvAEhtZU8vgl6lKpQ86KCDAFiextatW8XypRdC9qdUO8KOGTNG\nPCJ1jxgg3YPMBlqtnZ2dNlF4X0B316Jb/urfej0Uj8dT8PpIPYHKttAz2n///YXh4Xhm+Oa9996T\ndMdx48YBSI1vVfCpYvfu3ZLqe9tttwEonzhbxZw5c2wMpBNbp/6tj2cK9RcvXlw2hseJWeT88/l8\ntj3B1LCczp6q56K3r94brilcz9T05d6mMj/00EMAUrQ9qyKzhhDXLlVMzzmjhpC5BvNVrTqsygR0\nRpVh//b2dtvO4X6/X9hNnoNMUjQaxdNPPw3A2l8rF8yYMSPtf7IBap0h/mZ1dbWwMXpf9pT1jsVi\n8nxQExT06u/FWGtVxkN/BnR37TqL2NHRISwZWZy//OUvAFLPZFbXdoK+/uZbZTlTAo4OMlAXXHCB\nsFAMtRHqGqxW3adtQYacMhgV6lqqR0+4PgHdRx0Mw2NgYGBgYGDQ75HV5aYFdccdd4hmQY+bOgmI\n1T1ACMZUx44dKzsf85jFixen6XkA4MUXXwSQSv+kRojan1gsJjFolSUB7FZlIeBk2ariYrXdQGbt\ni15pmW2IRqPyG6q+oi9oeDKlDKreo5MH5lREjGOgHLtvqx4ChXCbNm0ST0PdZwhIiUTptTjtrk79\niLrPFr0x7uz73nvvFa09uWL69OkyN5z2RXNi3dh3+t5nRxxxRNGvNx8EAgEbs+MkpswmZCbj4Ha7\nheFh/02ZMsXGVOcLfn/jxo22PZyouRk3bpyMIY7H0aNHp+lz1DYmEgnRx5DFaWxsFIZKfw2HwzaP\n3+/329rGc7a3t+e1FulCWVXPyd8is+p2u+V4p53R9b231PVFZ2pisZiMWR5fXV2dtnN6KdCTe6Zq\nZVSW6IYbbgBg6V0PPvhgAJCq2JnAc5Cx7mlKuip+Zz/wvpGRueiii0TgT4wbNw6nnHIKAEuMTyQS\nCel39s+ee+4pkR59fzd1Z3R1TJD95HX9/e9/l+8YhsfAwMDAwMDgc4+sDM+5554LIMXKME5GrQxf\n1UJttAoHDRokab60TKmo/uSTT/Dggw8CsAo/Pfnkk+LJ8LzTpk0DABx77LE2676iokJYFYIWrc/n\nK4r6Xkc0GrV5DOpWEHoMNRaLpRVbApzT7Onx9AX4fD5HT5n/5+LBqAxRX9lmgizNhg0bbNoH9Rp1\nzzGRSIhXoXooQIoh0lmivsDw1NbWitbFKRNQ1+uo4GecuyNHjpT7Q2+9VKAmMBgM2tjDyspK29Yv\nKqPnVCJCb7fTFgfcef3QQw+V9vZW90GWJRgMCmuuz62mpiasXbsWgMWyqWyJk2aQx6njmesMP+Pa\nOmzYMNGicc3u7Oy0Zb/wnnd2dkoWY0/w17/+Ne1/tW/0zKp4PG67x+p6qWc/qexztl3S2Sav1yvr\ndDGZc5U95VrOLMdRo0ZJv+pwuqYbb7xRrplrllogklBZWr1ESr4lJbKlsU+dOhVAql06o//pp5+K\ntmzevHkAkFYmRm/nww8/jGeffRZAuhYHgC1KRPB+UmPWE11hVoOH6bVbt261iYpp0IRCIXlYcBI1\nNTXJBOEk48VHIhHplMcffxxAKg2NDwkaUFzAWlpa0ip0AqkJw4mqU9l+v19S4osJJ0Gqk7grG7Wu\nHq+ngurnKQe8Xq9NTJ3rNem0cWdnZ9nT0jnGWDsnEAhICEDfP0rtB3Xc6UYbjdURI0agvr4egCUm\nLSdI++6xxx4SftPrWTnR6Gq4gfP6z3/+MwDgjDPOEEekVOJlXoO6sOohUZ/PZ1ug1Y191YckoYqB\ngXSBrF6nxefzpTlUhUB7e7ss2DoqKyvld/i7oVDIVj2Y8Hg8tj3R+L4KGjDbt2+Xe8G2+nw+28OS\n/3d0dIjj2hN8+ctfTvufa3osFpM5wrEZi8VsRooaSnGSCOip6qosQBcmqwZPMSvXq+sjN7xVnSIa\nk9lExAyNH3nkkTJndQG40286Gfl77bVXj9sAWHX09tprL/zhD38AYDl5as0xloVhTaxwOCzjmskb\nTnXxnnjiCQApwT6Jj1xBQ9LJIDIhLQMDAwMDA4PPPbIyPPRYk8mkFC9jqi6pspaWFhG3UTDs9Xpt\n3ggt1QEDBohFzu9NmjRJrEIyR6ThKyoq5DiV6eHf9MS5i/GuXbuk6FIx4cRWOLEf2Rge1TOh90EP\noC9ADRvqXkSubI0aMih329ZApeEAAAkHSURBVOjtqBWH2UaOT706LWCxJfF4PI0iB4APP/wQADBh\nwgTxVinOrq6uFs+n1OAcUKl/nYFUQyFqNWZ+zjFJ8aHX68WkSZMAlI7h0cXFXq9X1iXC4/E4ermA\ncwKBGlLRmcuuri5hs9999135TZ1JLibC4bDNe+V6+FnCiSeemPY/1+xoNCr3ePHixQCAFStWyBgk\nE8V7HovFHPtL73N1l3fOQYbVxo4dK+FEHSNGjJC5mwuypWmrn+U7R+69914AqSrpOkvmBCcGk+8x\n8aKnYMHCe+65R0TKZMPJ8OzevVv6lCxWTU2Nra9uueUWAMD999+Pm2++GUBKqgKkdjjnzgu5gqFg\np+SX7iIQhuExMDAwMDAw6PfIyvC8+eabAIBVq1bhggsuAGCJkFmwLRKJiE6HbE5lZaVtvwtqf9Qt\nGRjH/Pjjj21aArVIFM+v6nporev6nnHjxvXIWs8FmazGTAJGNQXd6Vj9fIUsXV9IqLvY8/7m6uHq\nO713dnZKqi3HVanBe6tuc0LWiWNXLXnPtnP8qcJKxtlff/11AKmYN7VBHLtDhgwpG8NDwWBDQ4PM\nEX2Pm1AoJP2pMrH0nPg9sqfxeFyKgJYaKiulMzxut9tW1kHd582J9dHXG3Vckx34z3/+I+fKJN43\nyAydsWF0QO0P6jjvvPNOKdxJ9kfdgkjXzqnzk3OWUYeuri5J+b/99tsBADNnzsy4x9PJJ5+M++67\nL+d2ZWMRnApkcsfyMWPGYOnSpQCARx55xPbd66+/HoDFjN1+++2y119Poa5B+eCBBx4AkEo9P+CA\nA9LOxTmzY8cO6VPqahoaGmzFOa+88kp5ZRSIDOb3v/99OU4vR5AJ/C0nxq677+ZU+nbp0qXykLri\niisAWALQhoYG+WGGpTweT1rFT74HpC82XJx8Pp8cr+b/E/ybhkwoFBJxMxvIRXnDhg1YsWIFAKuq\naW/hlJEUi8UyhmjUyqeqoZBtojgZPOUWLaviNKf9v5yEzPqgVSve5rK5WzHBBZFjbefOnVLlVq/H\n4/f7pe+4AKvVaJk1wQq0LS0tcl69Sm45MH78eACpa+fcYN/QCBs5cqQYRk899RSA1EKkZ+kQwWBQ\nFr9SQzV4mD1FRKNRWUh5zap4VzdqVGE2X9VwCBdxGlZqLZJy9ulnDewzzp9MISUAuPrqq3H11Vc7\nfhYIBOQcashIN3i6q++lC7X50J03b16PDJ5Zs2bJ7/I3GXJUq1NzreDr+PHjpWIy68wxMej444/H\nkiVLAFhhuEz3IxOc1uHebtRcV1cn+1NSbsJn9IgRI+Sest0VFRW2pByuN2pmJ5/lqkGX7XnH+RkO\nh8Uh0YmNQCDQbXtNSMvAwMDAwMCg3yOru6J668888wwAyCtFR0uXLpU9YGh5ud3utHRAID0VkFYt\nLbr6+nqx/iiMcmI6SLF3dHTItT3//PMAgLfffhtA6cSUgD1so3qQ6s7MQHqVScKpKnFfCmlFIhGx\n5vW6Qk51MADYqvqq4ZN8ankUEmR4eL8bGxtlzHKcMizl9/ttXpuTUJvjtbm52bab9ahRo/DOO+8U\npS3dgYwNvVHA6gs15Z7XT8TjcVtVVvZzJBKRnYxLBZ2JAeyefEVFhXiAHH9kgLu6uhzDsXq1Yp4z\nGAwKs6nuLcXxodf/MsiMCy+8EIC1NxKZQzWEnwsikUivmYoPP/xQUuH1PdJeeumlHp2L0Y3a2lo5\nJ0uycPw1NTXJfCMz8rvf/Q4bNmwAkNrjDoDspzZ58mS5DrJAsVgs77pXlIuwpES+WLp0qYQaa2pq\nAFhzZ/fu3bY9M9WSMU7hZcoDzjrrLPmNXEJZ6txlv9GO0M+TDYbhMTAwMDAwMOj3yMrwZLO41qxZ\nAwAS3wOsFLg99thDrGhahSzi1dnZaauo2NfhFFvcvn27FDhUC9PxVS+MqIrsnFKfdQYl0++WEuvX\nr5c2OhV7UvU5gPP1qnuwMc23XKB3Qe9HFfTRa6Cn4vV6xXujPiQYDMp7ZIuolUkkEjZPhbqDcoCa\nhHvvvVf6iRoqp52HiYaGBmG96K2yHQMHDhQRaKmgVioH0nc/J1auXCkeNr0+vXie+p6aqq7vE7Rr\n1y4RohPxeNy2q7pB9+AzgBEAMhiDBg1yFO3qUFlypyrh+nqjrrV66vhzzz0njBPHM/V3TJXOFRT0\nOoFC65qaGmEZVWaE94LMDq9l9erVePjhhwFYjBCQf0VzMmKXXnopAGv/q55i48aNci8ppv7BD34A\nADjssMNk3uWKdevWAbDsh1yhrlO8d3oxzFyel2b2GhgYGBgYGPR7FDTlYPPmzbb38k2r6+sYPHiw\nZHPo+5aoHolTKXpd+7J161aJb5Mx4HmA7lPtioWOjg4sX74cgKXZYhuDwaDj7sO6romF+dasWZO1\nnHopMGHCBADWNanpk7xu9kMkEhE9GGPYXq9Xsit0jdbgwYNFu6O2udw46KCDbLob1WscPnx42mcj\nRowQjQ/HNb3QE044oeQ6LF6LqrnR95tjqm+xkEwm0/rZoGdgVh31KAMGDBDWgwgGg7atNjKlkecC\nfW168803hbEk03vXXXf1+LzdgUX0elpMr9BgRKWQbeSeV3wFIBEAbjkzefJkKdmhp8TX19fj4osv\nTntPzYDMBnXNYiFDXR+Zy47wrmw0kMvlKm9MpZdIJpPdFs3IpY1OKeXLli2TCUzqVjVuuEBSFKrW\n5tFDYLFYTAbH+vXrAVii0+5QqDZm+F5GmrC6ulrSnVVac8eOHWmvqtgwW4XSbOiujbm2Tw9zuN1u\n6QMamnyg19TUyKJRbBSzD1UcffTRAKw9fmbPni2UN8Xay5YtEyPo0UcfBWAlKvQGvW3jz372MwAp\ng5ShCM4RpyrmhcRNN90klWfpADjdk1L1YzmRz1xk/3Az6qamJhlvDB+qe10VAvpmo/Pnz8f9998P\nwHownnfeeQDShb2mD1Por200IS0DAwMDAwODfo+sDI+BgYGBgYGBQX+AYXgMDAwMDAwM+j2MwWNg\nYGBgYGDQ72EMHgMDAwMDA4N+D2PwGBgYGBgYGPR7GIPHwMDAwMDAoN/DGDwGBgYGBgYG/R7/AxzX\nmG0FDwFsAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 720x72 with 10 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0tVKxsAVuqGU","colab_type":"code","colab":{}},"source":["trainX = trainX.reshape(60000, 784)\n","testX = testX.reshape(10000,784)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sg5NredwvvSY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"6b1645b2-bf13-4db6-b017-d59f7e0b7b27","executionInfo":{"status":"ok","timestamp":1576399851814,"user_tz":-330,"elapsed":935,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(trainX.shape)\n","print(trainY.shape)\n","print(testX.shape)\n","print(testY.shape)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["(60000, 784)\n","(60000, 10)\n","(10000, 784)\n","(10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l4TbJGeSOIU4"},"source":["### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ac06XZZTOIU6","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.backend import backend"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hh_-EEt6bZmm","colab_type":"code","colab":{}},"source":["## hyperparameters\n","learning_rate = 0.01\n","hidden_nodes = 256\n","output_nodes = 10\n","        \n","model = Sequential()\n","model.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\n","model.add(Dense(hidden_nodes, activation='relu'))\n","model.add(Dense(output_nodes, activation='softmax'))\n","    \n","sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3hQpLv3aOIU_"},"source":["## Execute the model using model.fit()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O59C_-IgOIVB","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"70a35743-1c5d-495f-81d9-2540849daae2","executionInfo":{"status":"ok","timestamp":1576400137944,"user_tz":-330,"elapsed":55345,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 1s 19us/sample - loss: 112.1227 - acc: 0.0923 - val_loss: 8303.6572 - val_acc: 0.1000\n","Epoch 2/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 8258.8682 - acc: 0.1000 - val_loss: 185656.1094 - val_acc: 0.1000\n","Epoch 3/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 186283.6875 - acc: 0.1000 - val_loss: 391372.0000 - val_acc: 0.1000\n","Epoch 4/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 393777.4375 - acc: 0.1000 - val_loss: 438842752.0000 - val_acc: 0.1000\n","Epoch 5/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 433830080.0000 - acc: 0.1000 - val_loss: 1488427941888.0000 - val_acc: 0.1000\n","Epoch 6/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 1492487372800.0000 - acc: 0.1000 - val_loss: 3412708556800.0000 - val_acc: 0.1000\n","Epoch 7/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 3370670096384.0000 - acc: 0.1000 - val_loss: 2215224945934336.0000 - val_acc: 0.1000\n","Epoch 8/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 2213648827154432.0000 - acc: 0.1000 - val_loss: 499475232.0000 - val_acc: 0.1000\n","Epoch 9/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 499433664.0000 - acc: 0.1000 - val_loss: 10581942.0000 - val_acc: 0.1000\n","Epoch 10/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 10581886.0000 - acc: 0.1000 - val_loss: 20775158.0000 - val_acc: 0.1000\n","Epoch 11/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 20775088.0000 - acc: 0.1000 - val_loss: 28968826.0000 - val_acc: 0.1000\n","Epoch 12/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 28968708.0000 - acc: 0.1000 - val_loss: 33902820.0000 - val_acc: 0.1000\n","Epoch 13/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 33902560.0000 - acc: 0.1000 - val_loss: 34636012.0000 - val_acc: 0.1000\n","Epoch 14/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 34635688.0000 - acc: 0.1000 - val_loss: 30502290.0000 - val_acc: 0.1000\n","Epoch 15/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 30501822.0000 - acc: 0.1000 - val_loss: 21065488.0000 - val_acc: 0.1000\n","Epoch 16/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 21064936.0000 - acc: 0.1000 - val_loss: 6073174.0000 - val_acc: 0.1000\n","Epoch 17/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 6072448.5000 - acc: 0.1000 - val_loss: 3486.0908 - val_acc: 0.1000\n","Epoch 18/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3114 - acc: 0.1000 - val_loss: 3815.6147 - val_acc: 0.1000\n","Epoch 19/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3134 - acc: 0.1000 - val_loss: 4128.2764 - val_acc: 0.1000\n","Epoch 20/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3153 - acc: 0.1000 - val_loss: 4423.2622 - val_acc: 0.1000\n","Epoch 21/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3171 - acc: 0.1000 - val_loss: 4699.9580 - val_acc: 0.1000\n","Epoch 22/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3189 - acc: 0.1000 - val_loss: 4958.1289 - val_acc: 0.1000\n","Epoch 23/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3204 - acc: 0.1000 - val_loss: 5198.0073 - val_acc: 0.1000\n","Epoch 24/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3219 - acc: 0.1000 - val_loss: 5420.0845 - val_acc: 0.1000\n","Epoch 25/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3232 - acc: 0.1000 - val_loss: 5625.0449 - val_acc: 0.1000\n","Epoch 26/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3244 - acc: 0.1000 - val_loss: 5813.6509 - val_acc: 0.1000\n","Epoch 27/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3255 - acc: 0.1000 - val_loss: 5986.8281 - val_acc: 0.1000\n","Epoch 28/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3264 - acc: 0.1000 - val_loss: 6145.4233 - val_acc: 0.1000\n","Epoch 29/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3272 - acc: 0.1000 - val_loss: 6290.4648 - val_acc: 0.1000\n","Epoch 30/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3280 - acc: 0.1000 - val_loss: 6422.8486 - val_acc: 0.1000\n","Epoch 31/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3286 - acc: 0.1000 - val_loss: 6543.5210 - val_acc: 0.1000\n","Epoch 32/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3291 - acc: 0.1000 - val_loss: 6653.3540 - val_acc: 0.1000\n","Epoch 33/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 2.3295 - acc: 0.1000 - val_loss: 6752.9648 - val_acc: 0.1000\n","Epoch 34/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3299 - acc: 0.1000 - val_loss: 6843.6304 - val_acc: 0.1000\n","Epoch 35/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3302 - acc: 0.1000 - val_loss: 6925.8970 - val_acc: 0.1000\n","Epoch 36/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3304 - acc: 0.1000 - val_loss: 7000.4937 - val_acc: 0.1000\n","Epoch 37/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3306 - acc: 0.1000 - val_loss: 7068.0610 - val_acc: 0.1000\n","Epoch 38/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3307 - acc: 0.1000 - val_loss: 7129.2417 - val_acc: 0.1000\n","Epoch 39/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3307 - acc: 0.1000 - val_loss: 7184.5698 - val_acc: 0.1000\n","Epoch 40/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 2.3307 - acc: 0.1000 - val_loss: 7234.6143 - val_acc: 0.1000\n","Epoch 41/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3307 - acc: 0.1000 - val_loss: 7279.8345 - val_acc: 0.1000\n","Epoch 42/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3306 - acc: 0.1000 - val_loss: 7320.6880 - val_acc: 0.1000\n","Epoch 43/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3306 - acc: 0.1000 - val_loss: 7357.6016 - val_acc: 0.1000\n","Epoch 44/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3304 - acc: 0.1000 - val_loss: 7390.9102 - val_acc: 0.1000\n","Epoch 45/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3303 - acc: 0.1000 - val_loss: 7420.9790 - val_acc: 0.1000\n","Epoch 46/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3301 - acc: 0.1000 - val_loss: 7448.0879 - val_acc: 0.1000\n","Epoch 47/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 2.3299 - acc: 0.1000 - val_loss: 7472.5576 - val_acc: 0.1000\n","Epoch 48/50\n","60000/60000 [==============================] - 1s 17us/sample - loss: 2.3297 - acc: 0.1000 - val_loss: 7494.6313 - val_acc: 0.1000\n","Epoch 49/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3295 - acc: 0.1000 - val_loss: 7514.5063 - val_acc: 0.1000\n","Epoch 50/50\n","60000/60000 [==============================] - 1s 18us/sample - loss: 2.3292 - acc: 0.1000 - val_loss: 7532.4434 - val_acc: 0.1000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f377d310320>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JdzDtGwDOIVF"},"source":["### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kndfpdidOIVI","colab":{}},"source":["## hyperparameters\n","learning_rate = 0.01\n","hidden_nodes = 256\n","output_nodes = 10\n","        \n","model1 = Sequential()\n","model1.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\n","model1.add(tf.keras.layers.BatchNormalization())\n","model1.add(Dense(hidden_nodes, activation='relu'))\n","model1.add(Dense(output_nodes, activation='softmax'))\n","    \n","sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n","# Compile model\n","model1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mwk3T5LJOIVN"},"source":["### Execute the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JNLR8tcBOIVP","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a541066c-6af6-4ff9-cd22-44c7d225d5e8","executionInfo":{"status":"ok","timestamp":1576401759844,"user_tz":-330,"elapsed":65887,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["model1.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 2s 25us/sample - loss: 2.8977 - acc: 0.0578 - val_loss: 15.3551 - val_acc: 0.1516\n","Epoch 2/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.6842 - acc: 0.0843 - val_loss: 9.2841 - val_acc: 0.1926\n","Epoch 3/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.3301 - acc: 0.1864 - val_loss: 6.4437 - val_acc: 0.2640\n","Epoch 4/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.9460 - acc: 0.3587 - val_loss: 5.0161 - val_acc: 0.3617\n","Epoch 5/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.6161 - acc: 0.4880 - val_loss: 4.2801 - val_acc: 0.4287\n","Epoch 6/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.3683 - acc: 0.5625 - val_loss: 3.8416 - val_acc: 0.4829\n","Epoch 7/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.1948 - acc: 0.6079 - val_loss: 3.5333 - val_acc: 0.5211\n","Epoch 8/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.0765 - acc: 0.6414 - val_loss: 3.2622 - val_acc: 0.5461\n","Epoch 9/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9959 - acc: 0.6628 - val_loss: 2.9861 - val_acc: 0.5674\n","Epoch 10/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9390 - acc: 0.6794 - val_loss: 2.7015 - val_acc: 0.5858\n","Epoch 11/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.8957 - acc: 0.6932 - val_loss: 2.4258 - val_acc: 0.6065\n","Epoch 12/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.8599 - acc: 0.7046 - val_loss: 2.1855 - val_acc: 0.6218\n","Epoch 13/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.8289 - acc: 0.7134 - val_loss: 1.9982 - val_acc: 0.6310\n","Epoch 14/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.8013 - acc: 0.7222 - val_loss: 1.8632 - val_acc: 0.6395\n","Epoch 15/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.7763 - acc: 0.7303 - val_loss: 1.7670 - val_acc: 0.6472\n","Epoch 16/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.7536 - acc: 0.7370 - val_loss: 1.6932 - val_acc: 0.6535\n","Epoch 17/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.7327 - acc: 0.7435 - val_loss: 1.6319 - val_acc: 0.6617\n","Epoch 18/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.7134 - acc: 0.7496 - val_loss: 1.5811 - val_acc: 0.6686\n","Epoch 19/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6957 - acc: 0.7563 - val_loss: 1.5419 - val_acc: 0.6752\n","Epoch 20/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.6795 - acc: 0.7616 - val_loss: 1.5139 - val_acc: 0.6816\n","Epoch 21/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6651 - acc: 0.7672 - val_loss: 1.4929 - val_acc: 0.6857\n","Epoch 22/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6523 - acc: 0.7711 - val_loss: 1.4710 - val_acc: 0.6901\n","Epoch 23/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6408 - acc: 0.7746 - val_loss: 1.4403 - val_acc: 0.6944\n","Epoch 24/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6304 - acc: 0.7775 - val_loss: 1.3959 - val_acc: 0.6994\n","Epoch 25/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6206 - acc: 0.7807 - val_loss: 1.3371 - val_acc: 0.7037\n","Epoch 26/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6111 - acc: 0.7839 - val_loss: 1.2670 - val_acc: 0.7117\n","Epoch 27/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.6020 - acc: 0.7867 - val_loss: 1.1912 - val_acc: 0.7192\n","Epoch 28/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.5935 - acc: 0.7904 - val_loss: 1.1158 - val_acc: 0.7266\n","Epoch 29/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5855 - acc: 0.7934 - val_loss: 1.0453 - val_acc: 0.7344\n","Epoch 30/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5783 - acc: 0.7967 - val_loss: 0.9830 - val_acc: 0.7416\n","Epoch 31/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5718 - acc: 0.7992 - val_loss: 0.9303 - val_acc: 0.7468\n","Epoch 32/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5658 - acc: 0.8014 - val_loss: 0.8874 - val_acc: 0.7534\n","Epoch 33/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5602 - acc: 0.8034 - val_loss: 0.8535 - val_acc: 0.7585\n","Epoch 34/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5550 - acc: 0.8055 - val_loss: 0.8273 - val_acc: 0.7613\n","Epoch 35/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.5500 - acc: 0.8072 - val_loss: 0.8069 - val_acc: 0.7627\n","Epoch 36/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.5453 - acc: 0.8090 - val_loss: 0.7906 - val_acc: 0.7648\n","Epoch 37/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5407 - acc: 0.8109 - val_loss: 0.7768 - val_acc: 0.7654\n","Epoch 38/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5364 - acc: 0.8123 - val_loss: 0.7638 - val_acc: 0.7661\n","Epoch 39/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5322 - acc: 0.8134 - val_loss: 0.7509 - val_acc: 0.7674\n","Epoch 40/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5282 - acc: 0.8148 - val_loss: 0.7374 - val_acc: 0.7701\n","Epoch 41/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5243 - acc: 0.8162 - val_loss: 0.7236 - val_acc: 0.7734\n","Epoch 42/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5206 - acc: 0.8176 - val_loss: 0.7097 - val_acc: 0.7759\n","Epoch 43/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5170 - acc: 0.8194 - val_loss: 0.6961 - val_acc: 0.7772\n","Epoch 44/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5137 - acc: 0.8205 - val_loss: 0.6833 - val_acc: 0.7796\n","Epoch 45/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.5104 - acc: 0.8222 - val_loss: 0.6715 - val_acc: 0.7808\n","Epoch 46/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5074 - acc: 0.8233 - val_loss: 0.6609 - val_acc: 0.7833\n","Epoch 47/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5044 - acc: 0.8247 - val_loss: 0.6514 - val_acc: 0.7848\n","Epoch 48/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5015 - acc: 0.8257 - val_loss: 0.6429 - val_acc: 0.7867\n","Epoch 49/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4986 - acc: 0.8269 - val_loss: 0.6352 - val_acc: 0.7880\n","Epoch 50/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4959 - acc: 0.8282 - val_loss: 0.6281 - val_acc: 0.7893\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3776520fd0>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Py-KwkmjOIVU"},"source":["### Customize the learning rate to 0.001 in sgd optimizer and run the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yLXUE9jWOIVV","colab":{}},"source":["## hyperparameters\n","learning_rate = 0.001\n","hidden_nodes = 256\n","output_nodes = 10\n","        \n","model2 = Sequential()\n","model2.add(Dense(hidden_nodes, input_shape=(784,), activation='relu'))\n","model2.add(tf.keras.layers.BatchNormalization())\n","model2.add(Dense(hidden_nodes, activation='relu'))\n","model2.add(Dense(output_nodes, activation='softmax'))\n","    \n","sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n","# Compile model\n","model2.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pJUqA5T4OIVc","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"dd41bea9-4b38-496d-f06d-4fe0864dd903","executionInfo":{"status":"ok","timestamp":1576401854007,"user_tz":-330,"elapsed":66010,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["model2.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 2s 26us/sample - loss: 2.8495 - acc: 0.0966 - val_loss: 20.0115 - val_acc: 0.1165\n","Epoch 2/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.8286 - acc: 0.0991 - val_loss: 14.2026 - val_acc: 0.1246\n","Epoch 3/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.7891 - acc: 0.1037 - val_loss: 11.3786 - val_acc: 0.1345\n","Epoch 4/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.7338 - acc: 0.1110 - val_loss: 9.5459 - val_acc: 0.1461\n","Epoch 5/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 2.6652 - acc: 0.1198 - val_loss: 8.1928 - val_acc: 0.1612\n","Epoch 6/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.5861 - acc: 0.1327 - val_loss: 7.1229 - val_acc: 0.1800\n","Epoch 7/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.4990 - acc: 0.1488 - val_loss: 6.2426 - val_acc: 0.1979\n","Epoch 8/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.4066 - acc: 0.1708 - val_loss: 5.5022 - val_acc: 0.2170\n","Epoch 9/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.3113 - acc: 0.1973 - val_loss: 4.8735 - val_acc: 0.2368\n","Epoch 10/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.2154 - acc: 0.2304 - val_loss: 4.3391 - val_acc: 0.2587\n","Epoch 11/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.1207 - acc: 0.2678 - val_loss: 3.8869 - val_acc: 0.2837\n","Epoch 12/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 2.0288 - acc: 0.3090 - val_loss: 3.5071 - val_acc: 0.3116\n","Epoch 13/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.9408 - acc: 0.3504 - val_loss: 3.1911 - val_acc: 0.3428\n","Epoch 14/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.8578 - acc: 0.3886 - val_loss: 2.9295 - val_acc: 0.3740\n","Epoch 15/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.7800 - acc: 0.4218 - val_loss: 2.7129 - val_acc: 0.4023\n","Epoch 16/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.7078 - acc: 0.4515 - val_loss: 2.5333 - val_acc: 0.4263\n","Epoch 17/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.6410 - acc: 0.4793 - val_loss: 2.3839 - val_acc: 0.4462\n","Epoch 18/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.5796 - acc: 0.5035 - val_loss: 2.2583 - val_acc: 0.4624\n","Epoch 19/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.5233 - acc: 0.5253 - val_loss: 2.1517 - val_acc: 0.4777\n","Epoch 20/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.4718 - acc: 0.5457 - val_loss: 2.0604 - val_acc: 0.4892\n","Epoch 21/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.4247 - acc: 0.5634 - val_loss: 1.9811 - val_acc: 0.5008\n","Epoch 22/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.3816 - acc: 0.5789 - val_loss: 1.9115 - val_acc: 0.5110\n","Epoch 23/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.3423 - acc: 0.5937 - val_loss: 1.8496 - val_acc: 0.5236\n","Epoch 24/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.3063 - acc: 0.6054 - val_loss: 1.7938 - val_acc: 0.5353\n","Epoch 25/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.2733 - acc: 0.6160 - val_loss: 1.7428 - val_acc: 0.5443\n","Epoch 26/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.2431 - acc: 0.6260 - val_loss: 1.6956 - val_acc: 0.5543\n","Epoch 27/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.2154 - acc: 0.6347 - val_loss: 1.6514 - val_acc: 0.5627\n","Epoch 28/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.1898 - acc: 0.6424 - val_loss: 1.6093 - val_acc: 0.5713\n","Epoch 29/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.1663 - acc: 0.6486 - val_loss: 1.5690 - val_acc: 0.5772\n","Epoch 30/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.1445 - acc: 0.6539 - val_loss: 1.5301 - val_acc: 0.5840\n","Epoch 31/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.1243 - acc: 0.6595 - val_loss: 1.4924 - val_acc: 0.5895\n","Epoch 32/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.1054 - acc: 0.6630 - val_loss: 1.4558 - val_acc: 0.5954\n","Epoch 33/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0879 - acc: 0.6670 - val_loss: 1.4201 - val_acc: 0.6012\n","Epoch 34/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0714 - acc: 0.6701 - val_loss: 1.3854 - val_acc: 0.6063\n","Epoch 35/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0559 - acc: 0.6729 - val_loss: 1.3519 - val_acc: 0.6130\n","Epoch 36/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0413 - acc: 0.6758 - val_loss: 1.3195 - val_acc: 0.6175\n","Epoch 37/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0275 - acc: 0.6786 - val_loss: 1.2883 - val_acc: 0.6217\n","Epoch 38/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 1.0145 - acc: 0.6820 - val_loss: 1.2585 - val_acc: 0.6261\n","Epoch 39/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 1.0021 - acc: 0.6849 - val_loss: 1.2300 - val_acc: 0.6308\n","Epoch 40/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9904 - acc: 0.6877 - val_loss: 1.2030 - val_acc: 0.6356\n","Epoch 41/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9792 - acc: 0.6904 - val_loss: 1.1776 - val_acc: 0.6404\n","Epoch 42/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9686 - acc: 0.6934 - val_loss: 1.1536 - val_acc: 0.6454\n","Epoch 43/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9584 - acc: 0.6960 - val_loss: 1.1313 - val_acc: 0.6489\n","Epoch 44/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9488 - acc: 0.6984 - val_loss: 1.1105 - val_acc: 0.6541\n","Epoch 45/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9395 - acc: 0.7010 - val_loss: 1.0912 - val_acc: 0.6584\n","Epoch 46/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9307 - acc: 0.7035 - val_loss: 1.0734 - val_acc: 0.6611\n","Epoch 47/50\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.9223 - acc: 0.7060 - val_loss: 1.0569 - val_acc: 0.6638\n","Epoch 48/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9142 - acc: 0.7084 - val_loss: 1.0416 - val_acc: 0.6669\n","Epoch 49/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.9065 - acc: 0.7107 - val_loss: 1.0275 - val_acc: 0.6701\n","Epoch 50/50\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.8991 - acc: 0.7127 - val_loss: 1.0144 - val_acc: 0.6737\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f37763b7518>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j9CSqKvpOIVk"},"source":["### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GGAad54JOIVm","colab":{}},"source":["## hyperparameters\n","learning_rate = 0.03\n","        \n","model3 = Sequential()\n","model3.add(Dense(100,input_shape=(784,), activation='sigmoid'))\n","model3.add(tf.keras.layers.BatchNormalization())\n","model3.add(Dense(100, activation='sigmoid'))\n","model3.add(Dense(10, activation='softmax'))\n","    \n","sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n","# Compile model\n","model3.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MQ7oIymROIVp","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0ba441b3-b2f7-421d-d568-6c1a5a099c7e","executionInfo":{"status":"ok","timestamp":1576402151855,"user_tz":-330,"elapsed":32818,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["model3.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size = trainX.shape[0])"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 1s 15us/sample - loss: 2.6278 - acc: 0.0823 - val_loss: 2.4714 - val_acc: 0.1029\n","Epoch 2/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 2.5352 - acc: 0.1055 - val_loss: 2.3893 - val_acc: 0.1521\n","Epoch 3/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 2.3951 - acc: 0.1548 - val_loss: 2.3045 - val_acc: 0.2149\n","Epoch 4/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 2.2521 - acc: 0.2322 - val_loss: 2.2300 - val_acc: 0.2213\n","Epoch 5/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 2.1208 - acc: 0.3569 - val_loss: 2.1692 - val_acc: 0.3090\n","Epoch 6/50\n","60000/60000 [==============================] - 1s 11us/sample - loss: 2.0059 - acc: 0.4809 - val_loss: 2.1218 - val_acc: 0.3694\n","Epoch 7/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.9038 - acc: 0.5432 - val_loss: 2.0873 - val_acc: 0.3537\n","Epoch 8/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.8163 - acc: 0.5498 - val_loss: 2.0687 - val_acc: 0.3506\n","Epoch 9/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.7452 - acc: 0.5442 - val_loss: 2.0602 - val_acc: 0.2742\n","Epoch 10/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.6869 - acc: 0.5478 - val_loss: 2.0565 - val_acc: 0.2121\n","Epoch 11/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.6373 - acc: 0.5430 - val_loss: 2.0523 - val_acc: 0.1828\n","Epoch 12/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.5915 - acc: 0.5126 - val_loss: 2.0385 - val_acc: 0.1776\n","Epoch 13/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.5434 - acc: 0.4951 - val_loss: 2.0088 - val_acc: 0.1746\n","Epoch 14/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.4895 - acc: 0.5102 - val_loss: 1.9621 - val_acc: 0.1769\n","Epoch 15/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.4289 - acc: 0.5463 - val_loss: 1.9006 - val_acc: 0.1945\n","Epoch 16/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.3639 - acc: 0.5964 - val_loss: 1.8336 - val_acc: 0.2517\n","Epoch 17/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.3016 - acc: 0.6477 - val_loss: 1.7696 - val_acc: 0.3259\n","Epoch 18/50\n","60000/60000 [==============================] - 1s 11us/sample - loss: 1.2480 - acc: 0.6791 - val_loss: 1.7138 - val_acc: 0.3847\n","Epoch 19/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.2048 - acc: 0.6914 - val_loss: 1.6676 - val_acc: 0.5044\n","Epoch 20/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.1692 - acc: 0.6926 - val_loss: 1.6288 - val_acc: 0.5808\n","Epoch 21/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.1385 - acc: 0.6918 - val_loss: 1.5959 - val_acc: 0.6047\n","Epoch 22/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.1093 - acc: 0.6927 - val_loss: 1.5667 - val_acc: 0.6085\n","Epoch 23/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.0807 - acc: 0.6951 - val_loss: 1.5403 - val_acc: 0.6089\n","Epoch 24/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.0517 - acc: 0.6967 - val_loss: 1.5151 - val_acc: 0.6127\n","Epoch 25/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 1.0223 - acc: 0.7013 - val_loss: 1.4921 - val_acc: 0.6160\n","Epoch 26/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.9939 - acc: 0.7078 - val_loss: 1.4719 - val_acc: 0.6195\n","Epoch 27/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.9662 - acc: 0.7118 - val_loss: 1.4547 - val_acc: 0.6166\n","Epoch 28/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.9405 - acc: 0.7157 - val_loss: 1.4405 - val_acc: 0.6069\n","Epoch 29/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.9167 - acc: 0.7199 - val_loss: 1.4288 - val_acc: 0.5854\n","Epoch 30/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8956 - acc: 0.7270 - val_loss: 1.4192 - val_acc: 0.5465\n","Epoch 31/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8767 - acc: 0.7311 - val_loss: 1.4104 - val_acc: 0.5227\n","Epoch 32/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8595 - acc: 0.7349 - val_loss: 1.4010 - val_acc: 0.5086\n","Epoch 33/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8439 - acc: 0.7401 - val_loss: 1.3909 - val_acc: 0.4968\n","Epoch 34/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8295 - acc: 0.7411 - val_loss: 1.3776 - val_acc: 0.4961\n","Epoch 35/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8154 - acc: 0.7432 - val_loss: 1.3622 - val_acc: 0.5012\n","Epoch 36/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.8020 - acc: 0.7454 - val_loss: 1.3449 - val_acc: 0.5067\n","Epoch 37/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7894 - acc: 0.7475 - val_loss: 1.3265 - val_acc: 0.5179\n","Epoch 38/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7772 - acc: 0.7498 - val_loss: 1.3071 - val_acc: 0.5316\n","Epoch 39/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7661 - acc: 0.7508 - val_loss: 1.2882 - val_acc: 0.5492\n","Epoch 40/50\n","60000/60000 [==============================] - 1s 11us/sample - loss: 0.7557 - acc: 0.7519 - val_loss: 1.2700 - val_acc: 0.5716\n","Epoch 41/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7455 - acc: 0.7500 - val_loss: 1.2526 - val_acc: 0.5909\n","Epoch 42/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7359 - acc: 0.7512 - val_loss: 1.2369 - val_acc: 0.6110\n","Epoch 43/50\n","60000/60000 [==============================] - 1s 11us/sample - loss: 0.7270 - acc: 0.7519 - val_loss: 1.2223 - val_acc: 0.6345\n","Epoch 44/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7186 - acc: 0.7525 - val_loss: 1.2089 - val_acc: 0.6457\n","Epoch 45/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7106 - acc: 0.7539 - val_loss: 1.1967 - val_acc: 0.6544\n","Epoch 46/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.7028 - acc: 0.7563 - val_loss: 1.1853 - val_acc: 0.6548\n","Epoch 47/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.6955 - acc: 0.7575 - val_loss: 1.1737 - val_acc: 0.6576\n","Epoch 48/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.6884 - acc: 0.7599 - val_loss: 1.1624 - val_acc: 0.6591\n","Epoch 49/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.6817 - acc: 0.7655 - val_loss: 1.1518 - val_acc: 0.6583\n","Epoch 50/50\n","60000/60000 [==============================] - 1s 10us/sample - loss: 0.6753 - acc: 0.7678 - val_loss: 1.1412 - val_acc: 0.6522\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3776666198>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X-O-fFxnOIVt","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BiP7IL52OIVw","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Nr2YsZV0OIV0"},"source":["## Review model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h4ojW6-oOIV2","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"000cc75d-b78f-4cda-d1fc-242abe122583","executionInfo":{"status":"ok","timestamp":1576402322082,"user_tz":-330,"elapsed":3581,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(model.evaluate(trainX, trainY, verbose=0))\n","print(model.evaluate(testX, testY, verbose=0))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["[0.9806842393239339, 0.76463336]\n","[0.9985099328994751, 0.749]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QYxs22FY50y3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7b2661f5-6630-406e-bff5-c036d1956086","executionInfo":{"status":"ok","timestamp":1576402389897,"user_tz":-330,"elapsed":4423,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(model1.evaluate(trainX, trainY, verbose=0))\n","print(model1.evaluate(testX, testY, verbose=0))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["[0.5823219331304232, 0.80265]\n","[0.6280795967340469, 0.7893]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tHsDOxee56hz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"cd4d769c-1e24-40d1-c631-a51c558e37fd","executionInfo":{"status":"ok","timestamp":1576402410670,"user_tz":-330,"elapsed":4331,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(model2.evaluate(trainX, trainY, verbose=0))\n","print(model2.evaluate(testX, testY, verbose=0))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["[0.9812521351973216, 0.6838]\n","[1.0143625896453858, 0.6737]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3usTPPEg5_sl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"683b4dc9-69b1-4538-8814-5aa1042ae212","executionInfo":{"status":"ok","timestamp":1576402428532,"user_tz":-330,"elapsed":3467,"user":{"displayName":"Sajal Suryavanshi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCSCzp-PPFA-u9CgO8BtInJa_MzhV_71QerVAitHw=s64","userId":"16109277804996163317"}}},"source":["print(model3.evaluate(trainX, trainY, verbose=0))\n","print(model3.evaluate(testX, testY, verbose=0))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["[1.124451922194163, 0.66398335]\n","[1.1411731297492982, 0.6522]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FzHz8rO56YHe","colab_type":"code","colab":{}},"source":["# From above outputs, it can be inferred that model1 has the least loss value & hence is the best amongst all models designed."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gfFGmbZLOIV5"},"source":["### Run the model"]},{"cell_type":"code","metadata":{"id":"3SQ2TTH155uo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bIkbMEN5OIV7","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}